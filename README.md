# Auto Prompt Optimization

Repo: [GitHub](https://github.com/PRO-2684/Auto-Prompt-Optimize/)

## ü§î Introduction

This repository helps you to automate the process of inferring system prompts of a LLM app, given some of its `<input, output>` pairs. It has the following features:

- **Asynchronous**: Fully leverage your computer's power.
- **Controllable**: Name your own rate limit (RPM) and token limit per run, and the program will respect it.
- **Track usage**: Automatically tracks how many tokens you've used and calculates estimated cost.

## üì• Setup

### üì¶ Dependencies

```bash
pip install -r requirements.txt
```

### ‚öôÔ∏è Configuration

Create a file named `config.json` in the root directory of this repo. Here's how your `config.json` should look like:

```jsonc
{
    "openai_key": "sk-...", // OpenAI API key (Required)
    "openai_endpoint": "https://api.openai.com", // OpenAI API endpoint
    "rpm": 60, // Requests per minute
    "cost_factor": 2e-06, // Cost factor
    "single_token_limit": 300000, // Token limit per run
    "tokens_used": 0, // Tokens used
    "cost": 0 // Total cost
}
```

## üìñ Usage

```text
$ python3 main.py --help
usage: main.py [-h] [-T TASK] [-r ROUNDS] [-p POPULATION] [-t TRAIN_SAMPLE] [-e EVAL_SAMPLE] [-c CROSS_RATIO] [-v]

options:
  -h, --help            show this help message and exit
  -T TASK, --task TASK  Path to the task directory.
  -r ROUNDS, --rounds ROUNDS
                        Maximum number of rounds to find the best prompt.
  -p POPULATION, --population POPULATION
                        Number of prompts to keep after each iteration.
  -t TRAIN_SAMPLE, --train-sample TRAIN_SAMPLE
                        Maximum number of examples to use when training on each iteration, default to 8.
  -e EVAL_SAMPLE, --eval-sample EVAL_SAMPLE
                        Maximum number of examples to use on evaluation, default to 32.
  -c CROSS_RATIO, --cross-ratio CROSS_RATIO
                        The ratio of cross-enhancement, default to 0.5.
  -v, --verbose         Increase verbosity.
```

The task directory shall be a folder containing the following files:

- `train-input.txt`: input examples
- `train-output.txt`: output examples
- `eval-input.txt`: input to be evaluated
- `eval-output.txt`: expected output

## üîÑÔ∏è Procedure

### Overview

1. Given $t$ samples from the training set, let the agent generate $k$ initial prompts.
2. [Evaluate](#evaluation) each prompt on randomly-selected $e$ samples from the training set.
3. Let the agent self-enhance each prompt based on corresponding evaluation result, so we now have $2k$ prompts.
4. Let the agent cross-enhance randomly-selected $\lfloor ck/2\rfloor$ prompt pairs, so we now have $2k + \lfloor ck/2\rfloor$ prompts.
5. [Evaluate](#evaluation) each prompt (if not already evaluated) on randomly-selected $e$ samples from the training set, and randomly select $k$ prompts with the weighted probability of their exponentiated scores. (so as to accentuate the differences)
6. Repeat steps 3-4 for $r$ rounds.
7. Select the best prompt with the highest score and evaluate it against the evaluation set.

### Evaluation

Given a prompt and a set of example inputs and outputs:

1. Generate real outputs using the prompt and given inputs.
2. Rate the similarity between the generated outputs and the expected outputs, and assign a score $\in\{0, 1, 2, 3, 4, 5\}$ to each output.
3. Assign the prompt's score as the average of aforementioned scores.

## üß™ Samples

- `sample/`: Contains sample tasks.
- `sample-log/`: Contains logs of sample tasks.
  - These logs are generated with the arguments provided in `dev.sh`.
  - Note that the structure of logs might differ, since some of them are generated by the previous version of the program.

## üéâ Acknowledgements

- [microsoft/EvoPrompt: Automatic Prompt Optimization (github.com)](https://github.com/microsoft/EvoPrompt)
- [HouYi (github.com)](https://github.com/LLMSecurity/HouYi)
- [openai/openai-python: The official Python library for the OpenAI API (github.com)](https://github.com/openai/openai-python)
- [litl/backoff: Python library providing function decorators for configurable backoff and retry (github.com)](https://github.com/litl/backoff)
- [tomasbasham/ratelimit: API Rate Limit Decorator (github.com)](https://github.com/tomasbasham/ratelimit)
